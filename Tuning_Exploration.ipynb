{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb917831-dae4-44cb-a42a-1cebe68aafac",
   "metadata": {},
   "source": [
    "# Hyperparam Tuning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eee5192-a51a-4d02-aa9c-bce6afc2bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.00000001 for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e2ce6f-f3b6-4077-be6b-be173366b620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 1e-08, 1e-08, 1e-08]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b2c6f7-0c5b-4cb9-a088-a7a60bdfd739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Unity environment took too long to respond. Make sure that :\n",
      "\t The environment does not need user interaction to launch\n",
      "\t The Academy and the External Brain(s) are attached to objects in the Scene\n",
      "\t The environment and the Python interface have compatible versions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started UnityEnvironment on worker id 1\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from unityagents.exception import UnityTimeOutException\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from pathlib import Path\n",
    "#filename = Path(\"./envs/V1/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "#filename = Path(\"./envs/V2/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "filename = Path(\"./envs/V2//Reacher.x86_64\") \n",
    "filename_abs= filename.resolve()\n",
    "\n",
    "def start_unity_env(filename, no_graphics=True):\n",
    "    env = None\n",
    "\n",
    "    def start_unity_env_id(filename, no_graphics=True, worker_id=0):\n",
    "        try:\n",
    "            env = UnityEnvironment(file_name=str(filename_abs),no_graphics=no_graphics, worker_id=worker_id)\n",
    "            print(\"Started UnityEnvironment on worker id {}\".format(worker_id))\n",
    "            return True, env\n",
    "        except UnityTimeOutException as e:\n",
    "            print(e)\n",
    "            return False, None\n",
    "        \n",
    "    max_worker_id=10\n",
    "    for i in range(max_worker_id):\n",
    "        env_started, env = start_unity_env_id(filename, no_graphics=True, worker_id=i)\n",
    "        if env_started:\n",
    "            print(env)\n",
    "            return env\n",
    "    \n",
    "    return None\n",
    "\n",
    "env = start_unity_env(filename=str(filename_abs), no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f49dbf-88b6-4320-893d-90628285a346",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'port'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5ceabb8f13fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'port'"
     ]
    }
   ],
   "source": [
    "env.port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6362aa1c-295c-4b1e-9cca-608bbb8629b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "def run_configured_ddpg(env, config, training_name):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    # get the default brain\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "    # reset the environment\n",
    "    env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "    # number of agents\n",
    "    num_agents = len(env_info.agents)\n",
    "    print('Number of agents:', num_agents)\n",
    "    # size of each action\n",
    "    action_size = brain.vector_action_space_size\n",
    "    print('Size of each action:', action_size)\n",
    "    # examine the state space \n",
    "    states = env_info.vector_observations\n",
    "    state_size = states.shape[1]\n",
    "    print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "    print('The state for the first agent looks like:', states[0])\n",
    "    \n",
    "    #ep_tot_ts = []\n",
    "    n_episodes=500\n",
    "    max_t=1500\n",
    "    average_score_over=100\n",
    "    num_agents = len(env_info.agents)\n",
    "    config['num_agents']=num_agents\n",
    "    \n",
    "    \n",
    "    agent = Agent(state_size=state_size,\n",
    "                  action_size=action_size,\n",
    "                  random_seed=config['random_seed'],\n",
    "                  config=config,\n",
    "                  device=device)\n",
    "\n",
    "\n",
    "    #Load model\n",
    "    load_model = False\n",
    "    actor_path = 'checkpoint_actor_12p78.pth'\n",
    "    critic_path = 'checkpoint_critic_12p78.pth'\n",
    "    #actor_path = 'checkpoint_actor_p98.pth'\n",
    "    #critic_path = 'checkpoint_critic_p98.pth'\n",
    "    #actor_path = 'checkpoint_actor_p73.pth'\n",
    "    #critic_path = 'checkpoint_critic_p73.pth'\n",
    "    #actor_path = 'checkpoint_actor.pth'\n",
    "    #critic_path = 'checkpoint_critic.pth'\n",
    "\n",
    "    if load_model:\n",
    "        agent.actor_local.load_state_dict(torch.load(actor_path))\n",
    "        agent.actor_target.load_state_dict(torch.load(actor_path))\n",
    "        agent.critic_local.load_state_dict(torch.load(critic_path))\n",
    "        agent.critic_target.load_state_dict(torch.load(critic_path))\n",
    "\n",
    "    #Load Score\n",
    "    import pickle\n",
    "    load_scores = False\n",
    "    if load_scores:\n",
    "        scores_deque = pickle.load(open('scores_deque.pkl', 'rb'))\n",
    "        scores = pickle.load(open('scores.pkl', 'rb'))\n",
    "    else:\n",
    "        scores_deque = deque(maxlen=average_score_over)\n",
    "        scores = []\n",
    "\n",
    "        #===================================================================\n",
    "        def run_episode(env, agent, config, num_agents, brain_name):\n",
    "            env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "            states = env_info.vector_observations\n",
    "            agent.reset()\n",
    "            agent_scores = np.zeros(num_agents) \n",
    "            #print(f'Starting Episode {i_episode}') \n",
    "            for t in range(max_t):\n",
    "                #print(t)\n",
    "\n",
    "                #noise_weight = np.clip(avg_score/30*-1+1.0, 0.0, 1.0)\n",
    "                actions = agent.act(states, add_noise=True, noise_weight=1.0)\n",
    "                env_info = env.step(actions)[brain_name]\n",
    "                next_states = env_info.vector_observations\n",
    "                rewards = env_info.rewards\n",
    "                dones = env_info.local_done\n",
    "\n",
    "                if t%config['train_every_ts'] == 0:\n",
    "                    agent.step(states,\n",
    "                               actions,\n",
    "                               rewards,\n",
    "                               next_states,\n",
    "                               dones,\n",
    "                               add_replay_flag=True,\n",
    "                               learn_flag=True,\n",
    "                               learn_repeat=config['train_repeated'])\n",
    "                else:\n",
    "                    agent.step(states,\n",
    "                               actions,\n",
    "                               rewards,\n",
    "                               next_states,\n",
    "                               dones,\n",
    "                               add_replay_flag=True,\n",
    "                               learn_flag=False,\n",
    "                               learn_repeat=config['train_repeated'])\n",
    "\n",
    "                states = next_states\n",
    "                agent_scores += rewards\n",
    "                #if True in dones:\n",
    "                #    ep_tot_ts.append(t)\n",
    "                #    break\n",
    "\n",
    "                #if t % 100 == 0:\n",
    "                #    print('\\r {} ts \\tAverage Score: {:.2f}, Noise: {}'.format(t, np.mean(agent_scores), 1))#agent.noise.state))\n",
    "\n",
    "\n",
    "            return agent_scores  \n",
    "        \n",
    "        \n",
    "        def run_ddpg(agent, env, config, training_name, num_agents, brain_name):\n",
    "            avg_score = 0\n",
    "            best_score = 0\n",
    "            for i_episode in range(1, n_episodes+1):\n",
    "                agent_scores = run_episode(env, agent, config, num_agents, brain_name)\n",
    "\n",
    "                avg_score = np.mean(agent_scores) \n",
    "                scores_deque.append(avg_score)   \n",
    "                scores.append(avg_score)\n",
    "\n",
    "                avg_100_scores = np.mean(scores_deque)\n",
    "\n",
    "                #Save successful agents\n",
    "                if avg_100_scores >= 30.0:\n",
    "                        print(\"Success!\")\n",
    "                        torch.save(agent.actor_local.state_dict(), \"successful_checkpoint_actor_\"+training_name+\".pth\")   \n",
    "                        torch.save(agent.critic_local.state_dict(), \"successful_checkpoint_critic_\"+training_name+\".pth\") \n",
    "\n",
    "                #Save every 10 episodes if current episodes greater than \n",
    "                if i_episode % 10 == 0:\n",
    "                    torch.save(agent.actor_local.state_dict(), \"checkpoint_actor_\"+training_name+\".pth\")\n",
    "                    torch.save(agent.critic_local.state_dict(), \"checkpoint_critic_\"+training_name+\".pth\")\n",
    "\n",
    "                    if avg_score > best_score:\n",
    "                        torch.save(agent.actor_local.state_dict(), \"checkpoint_actor_best_\"+training_name+\".pth\")\n",
    "                        torch.save(agent.critic_local.state_dict(), \"checkpoint_critic_best_\"+training_name+\".pth\")\n",
    "                        \n",
    "                    \n",
    "                    if False:\n",
    "                        print(\"Learning Samples: mean: {} : n_sample : {}\".format(agent.mean_learning_sample_reward, agent.n_learning_samples))\n",
    "                        avg_rewards_learning_sample = agent.mean_learning_sample_reward/ agent.n_learning_samples\n",
    "                        print('\\rAverage Reward in Internal Learning Samples: {}'.format(avg_rewards_learning_sample))\n",
    "\n",
    "                #Get average episodic scores\n",
    "                if i_episode % config['print_every'] == 0:\n",
    "                \n",
    "                    print('\\rScore Queue {},\\t Mean: {:.5f}'.format(scores_deque, avg_100_scores))\n",
    "                    print('\\rEpisode {},\\t Noise: {}'.format(i_episode,1.0))#agent.noise.state))\n",
    "                    try:\n",
    "                        if config['ray_tune']:\n",
    "                            train.report({\"avg_100_score\" : avg_100_scores})\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "            return scores\n",
    "        #===================================================================\n",
    "\n",
    "    return run_ddpg(agent, env, config, training_name, num_agents, brain_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd2f990-7a5d-4dee-a5bc-457944c26061",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "====================================================================\n",
      "====================================================================\n",
      "_tet_1_tr_1\n",
      "cuda:0\n",
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.92529297e+00 -1.00000000e+00\n",
      " -6.30408478e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  3.75728816e-01]\n",
      "Score Queue deque([0.42899999041110276, 0.3854999913834035, 0.3844999914057553, 0.5839999869465828, 0.6069999864324928, 0.9184999794699251, 1.196999973244965, 1.1819999735802411, 1.3604999695904554, 1.2349999723955989, 1.4564999674446881, 1.8094999595545231, 1.7619999606162309, 2.4619999449700116, 2.6514999407343565, 2.9179999347776175, 2.7174999392591417, 2.9724999335594475, 3.310999925993383, 3.577999920025468], maxlen=100),\t Mean: 1.69607\n",
      "Episode 20,\t Noise: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-92db4b5f4478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_configured_ddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtuning_run_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f0b74605e992>\u001b[0m in \u001b[0;36mrun_configured_ddpg\u001b[0;34m(env, config, training_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m#===================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_ddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f0b74605e992>\u001b[0m in \u001b[0;36mrun_ddpg\u001b[0;34m(agent, env, config, training_name, num_agents, brain_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0magent_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mavg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f0b74605e992>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(env, agent, config, num_agents, brain_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m                                \u001b[0madd_replay_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                \u001b[0mlearn_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                learn_repeat=config['train_repeated'])\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                     agent.step(states,\n",
      "\u001b[0;32m/mnt/data1/Projects/Udacity_RL/p2/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, states, actions, rewards, next_states, dones, add_replay_flag, learn_flag, learn_repeat)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data1/Projects/Udacity_RL/p2/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# ----------------------- update target networks ----------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drlnd/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drlnd/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drlnd/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drlnd/lib/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Manual Tuning\n",
    "\n",
    "config = {'buffer_size' : int(1e6),\n",
    "          'batch_size' : 128,\n",
    "          'gamma' : 0.95,\n",
    "          'tau' : 1e-3,\n",
    "          'lr_actor' : 1e-3,\n",
    "          'lr_critic' : 1e-4,\n",
    "          #'weight_decay' : 0.0,\n",
    "          'weight_decay' : 0.000008,\n",
    "          'theta' : 0.15,\n",
    "          'random_seed' : 10,\n",
    "          'train_every_ts' : 20,\n",
    "          'train_repeated' : 20,\n",
    "          'print_every' : 20}\n",
    "\n",
    "\n",
    "tuning_run_scores = {}\n",
    "#for train_every_ts in np.arange(10,20+1, step=10):\n",
    "for train_every_ts in np.arange(1, 11, step=10):\n",
    "    config['train_every_ts'] = train_every_ts\n",
    "    \n",
    "    for train_repeated in np.arange(1, 11, step=10):\n",
    "        config['train_repeated'] = train_repeated\n",
    "    \n",
    "        for i in range(3):\n",
    "            print('====================================================================')\n",
    "   \n",
    "        training_name='_tet_' +str(train_every_ts)+ '_tr_' +str(train_repeated)\n",
    "        print(training_name)\n",
    "        \n",
    "        score = run_configured_ddpg(env, config, training_name)\n",
    "        tuning_run_scores[training_name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24f9d0f6-4737-4e8c-9efc-560f885a2b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<slot wrapper '__str__' of 'object' objects>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50a196-dc9a-40ba-9c5e-c0c42eac7dd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 21:54:12,106\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-10-07 21:54:13,171\tINFO tune.py:219 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "/home/emcy/miniconda3/envs/drlnd/lib/python3.6/site-packages/ray/tune/experiment/experiment.py:171: UserWarning: The `local_dir` argument of `Experiment is deprecated. Use `storage_path` or set the `TUNE_RESULT_DIR` environment variable instead.\n",
      "  \"The `local_dir` argument of `Experiment is deprecated. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-10-07 22:36:56</td></tr>\n",
       "<tr><td>Running for: </td><td>00:42:43.20        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.1/62.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  lr_actor</th><th style=\"text-align: right;\">  lr_critic</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  avg_100_score</th><th style=\"text-align: right;\">  best_score</th><th style=\"text-align: right;\">  i_episode</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MyTrainable_947f8_00013</td><td>RUNNING   </td><td>192.168.1.51:2784756</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.001 </td><td style=\"text-align: right;\">     0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         36.6167</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00000</td><td>TERMINATED</td><td>192.168.1.51:2749683</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        172.218 </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00001</td><td>TERMINATED</td><td>192.168.1.51:2752194</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        184.945 </td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00002</td><td>TERMINATED</td><td>192.168.1.51:2754844</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        205.106 </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00003</td><td>TERMINATED</td><td>192.168.1.51:2757755</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.001 </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        171.97  </td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00004</td><td>TERMINATED</td><td>192.168.1.51:2760297</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.001 </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        186.644 </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00005</td><td>TERMINATED</td><td>192.168.1.51:2762970</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.001 </td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        207.506 </td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00006</td><td>TERMINATED</td><td>192.168.1.51:2765935</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.0001</td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        172.41  </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00007</td><td>TERMINATED</td><td>192.168.1.51:2768413</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.0001</td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        187.591 </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00008</td><td>TERMINATED</td><td>192.168.1.51:2771157</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.0001</td><td style=\"text-align: right;\">     0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        208.135 </td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00009</td><td>TERMINATED</td><td>192.168.1.51:2774105</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        174.053 </td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00010</td><td>TERMINATED</td><td>192.168.1.51:2776625</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        186.803 </td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00011</td><td>TERMINATED</td><td>192.168.1.51:2779322</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    0.01  </td><td style=\"text-align: right;\">     0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        207.537 </td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">          5</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00012</td><td>TERMINATED</td><td>192.168.1.51:2782264</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">    0.001 </td><td style=\"text-align: right;\">     0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        172.701 </td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td style=\"text-align: right;\">          5</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2749683)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE ID 947f8_00000\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00000\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2749683)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2749683)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  avg_100_score</th><th style=\"text-align: right;\">  best_score</th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_avg_score</th><th>hostname  </th><th style=\"text-align: right;\">  i_episode</th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip     </th><th>os_cwd                                                                                                                                                        </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MyTrainable_947f8_00000</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_21-57-08</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00000_0_batch_size=64,lr_actor=0.0100,lr_critic=0.0010_2023-10-07_21-54-13  </td><td style=\"text-align: right;\">2749683</td><td style=\"text-align: right;\">            172.218 </td><td style=\"text-align: right;\">           34.5145</td><td style=\"text-align: right;\">      172.218 </td><td style=\"text-align: right;\"> 1696730228</td><td style=\"text-align: right;\">                   5</td><td>947f8_00000</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00001</td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-00-17</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00001_1_batch_size=128,lr_actor=0.0100,lr_critic=0.0010_2023-10-07_21-57-09 </td><td style=\"text-align: right;\">2752194</td><td style=\"text-align: right;\">            184.945 </td><td style=\"text-align: right;\">           37.4751</td><td style=\"text-align: right;\">      184.945 </td><td style=\"text-align: right;\"> 1696730417</td><td style=\"text-align: right;\">                   5</td><td>947f8_00001</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00002</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-03-46</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00002_2_batch_size=256,lr_actor=0.0100,lr_critic=0.0010_2023-10-07_22-00-18 </td><td style=\"text-align: right;\">2754844</td><td style=\"text-align: right;\">            205.106 </td><td style=\"text-align: right;\">           42.1091</td><td style=\"text-align: right;\">      205.106 </td><td style=\"text-align: right;\"> 1696730626</td><td style=\"text-align: right;\">                   5</td><td>947f8_00002</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00003</td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-06-42</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00003_3_batch_size=64,lr_actor=0.0010,lr_critic=0.0010_2023-10-07_22-03-47  </td><td style=\"text-align: right;\">2757755</td><td style=\"text-align: right;\">            171.97  </td><td style=\"text-align: right;\">           34.571 </td><td style=\"text-align: right;\">      171.97  </td><td style=\"text-align: right;\"> 1696730802</td><td style=\"text-align: right;\">                   5</td><td>947f8_00003</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00004</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-09-53</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00004_4_batch_size=128,lr_actor=0.0010,lr_critic=0.0010_2023-10-07_22-06-43 </td><td style=\"text-align: right;\">2760297</td><td style=\"text-align: right;\">            186.644 </td><td style=\"text-align: right;\">           37.781 </td><td style=\"text-align: right;\">      186.644 </td><td style=\"text-align: right;\"> 1696730993</td><td style=\"text-align: right;\">                   5</td><td>947f8_00004</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00005</td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-13-25</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00005_5_batch_size=256,lr_actor=0.0010,lr_critic=0.0010_2023-10-07_22-09-54 </td><td style=\"text-align: right;\">2762970</td><td style=\"text-align: right;\">            207.506 </td><td style=\"text-align: right;\">           42.6563</td><td style=\"text-align: right;\">      207.506 </td><td style=\"text-align: right;\"> 1696731205</td><td style=\"text-align: right;\">                   5</td><td>947f8_00005</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00006</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-16-21</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00006_6_batch_size=64,lr_actor=0.0001,lr_critic=0.0010_2023-10-07_22-13-25  </td><td style=\"text-align: right;\">2765935</td><td style=\"text-align: right;\">            172.41  </td><td style=\"text-align: right;\">           34.7694</td><td style=\"text-align: right;\">      172.41  </td><td style=\"text-align: right;\"> 1696731381</td><td style=\"text-align: right;\">                   5</td><td>947f8_00006</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00007</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-19-32</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00007_7_batch_size=128,lr_actor=0.0001,lr_critic=0.0010_2023-10-07_22-16-21 </td><td style=\"text-align: right;\">2768413</td><td style=\"text-align: right;\">            187.591 </td><td style=\"text-align: right;\">           38.1186</td><td style=\"text-align: right;\">      187.591 </td><td style=\"text-align: right;\"> 1696731572</td><td style=\"text-align: right;\">                   5</td><td>947f8_00007</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00008</td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-23-03</td><td>True  </td><td style=\"text-align: right;\">               0.75</td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00008_8_batch_size=256,lr_actor=0.0001,lr_critic=0.0010_2023-10-07_22-19-32 </td><td style=\"text-align: right;\">2771157</td><td style=\"text-align: right;\">            208.135 </td><td style=\"text-align: right;\">           42.8797</td><td style=\"text-align: right;\">      208.135 </td><td style=\"text-align: right;\"> 1696731783</td><td style=\"text-align: right;\">                   5</td><td>947f8_00008</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00009</td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-26-01</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00009_9_batch_size=64,lr_actor=0.0100,lr_critic=0.0001_2023-10-07_22-23-04  </td><td style=\"text-align: right;\">2774105</td><td style=\"text-align: right;\">            174.053 </td><td style=\"text-align: right;\">           35.1406</td><td style=\"text-align: right;\">      174.053 </td><td style=\"text-align: right;\"> 1696731961</td><td style=\"text-align: right;\">                   5</td><td>947f8_00009</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00010</td><td style=\"text-align: right;\">           0.15</td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-29-12</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00010_10_batch_size=128,lr_actor=0.0100,lr_critic=0.0001_2023-10-07_22-26-02</td><td style=\"text-align: right;\">2776625</td><td style=\"text-align: right;\">            186.803 </td><td style=\"text-align: right;\">           37.8103</td><td style=\"text-align: right;\">      186.803 </td><td style=\"text-align: right;\"> 1696732152</td><td style=\"text-align: right;\">                   5</td><td>947f8_00010</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00011</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-32-44</td><td>True  </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00011_11_batch_size=256,lr_actor=0.0100,lr_critic=0.0001_2023-10-07_22-29-13</td><td style=\"text-align: right;\">2779322</td><td style=\"text-align: right;\">            207.537 </td><td style=\"text-align: right;\">           42.7857</td><td style=\"text-align: right;\">      207.537 </td><td style=\"text-align: right;\"> 1696732364</td><td style=\"text-align: right;\">                   5</td><td>947f8_00011</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00012</td><td style=\"text-align: right;\">           0.3 </td><td style=\"text-align: right;\">        0.75</td><td>2023-10-07_22-35-40</td><td>True  </td><td style=\"text-align: right;\">               0.75</td><td>EmcyRook  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                         5</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00012_12_batch_size=64,lr_actor=0.0010,lr_critic=0.0001_2023-10-07_22-32-44 </td><td style=\"text-align: right;\">2782264</td><td style=\"text-align: right;\">            172.701 </td><td style=\"text-align: right;\">           34.6431</td><td style=\"text-align: right;\">      172.701 </td><td style=\"text-align: right;\"> 1696732540</td><td style=\"text-align: right;\">                   5</td><td>947f8_00012</td></tr>\n",
       "<tr><td>MyTrainable_947f8_00013</td><td style=\"text-align: right;\">           0   </td><td style=\"text-align: right;\">        0   </td><td>2023-10-07_22-36-21</td><td>False </td><td style=\"text-align: right;\">               0   </td><td>EmcyRook  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                         1</td><td>192.168.1.51</td><td>/mnt/data1/Projects/ray_results/MyTrainable_2023-10-07_21-54-10/MyTrainable_947f8_00013_13_batch_size=128,lr_actor=0.0010,lr_critic=0.0001_2023-10-07_22-35-41</td><td style=\"text-align: right;\">2784756</td><td style=\"text-align: right;\">             36.6167</td><td style=\"text-align: right;\">           36.6167</td><td style=\"text-align: right;\">       36.6167</td><td style=\"text-align: right;\"> 1696732581</td><td style=\"text-align: right;\">                   1</td><td>947f8_00013</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2749683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2752194)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE ID 947f8_00001\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00001\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2752194)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2752194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2752194)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2754844)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE ID 947f8_00002\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00002\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2754844)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2754844)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2754844)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2757755)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE ID 947f8_00003\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00003\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2757755)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2757755)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2757755)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2760297)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE ID 947f8_00004\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00004\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2760297)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2760297)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2760297)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2762970)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE ID 947f8_00005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2762970)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2762970)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2762970)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2765935)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE ID 947f8_00006\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00006\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2765935)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m  -1.68164849e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2765935)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2765935)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2768413)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE ID 947f8_00007\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00007\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2768413)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2768413)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2768413)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2771157)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE ID 947f8_00008\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00008\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2771157)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Port: 5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2771157)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2771157)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2774105)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE ID 947f8_00009\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00009\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2774105)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2774105)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2774105)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2776625)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE ID 947f8_00010\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00010\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2776625)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2776625)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2776625)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2779322)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE ID 947f8_00011\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00011\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2779322)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2779322)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2779322)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2782264)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE ID 947f8_00012\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00012\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2782264)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m INFO:unityagents:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m 'Academy' started successfully!\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2782264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2782264)\u001b[0m Saving New Best Score: 0.7499999832361937\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE ID default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE NAME default\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2784756)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE ID 947f8_00013\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE NAME MyTrainable_947f8_00013\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE IP 192.168.1.51\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE IP_PID ('192.168.1.51', 2784756)\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m TRAINABLE STATE {'iteration': 0, 'timesteps_total': None, 'time_total': 0.0, 'episodes_total': None, 'last_result': None, 'ray_version': '2.4.0'}\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Found path: /mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Mono path[0] = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/Managed'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Mono config path = '/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m \tScreenSelector.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Logging to /home/emcy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Started UnityEnvironment on worker id 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Unity Academy name: Academy\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Number of Brains: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Number of External Brains : 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Lesson number : 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Reset Parameters :\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m \t\tgoal_size -> 5.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m \t\tgoal_speed -> 1.0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Unity brain name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Number of Visual Observations (per agent): 0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Observation space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Observation space size (per agent): 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Number of stacked Vector Observation: 1\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action space type: continuous\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action space size (per agent): 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m         Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m cuda:0\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Brain Name: ReacherBrain\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Port: 5005\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Number of agents: 20\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m Size of each action: 4\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m There are 20 agents. Each observes a state with length: 33\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m  -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m   5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "\u001b[2m\u001b[36m(MyTrainable pid=2784756)\u001b[0m  -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Noise: 1.0pid=2784756)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 22:36:57,396\tWARNING tune.py:185 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    }
   ],
   "source": [
    "#Ray Tuning\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune import Trainable\n",
    "from ray.air.config import RunConfig, CheckpointConfig\n",
    "from ray.tune import TuneConfig\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from unityagents.exception import UnityTimeOutException\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import time\n",
    "\n",
    "class MyTrainable(Trainable):\n",
    "    def setup(self, config):\n",
    "        print(\"TRAINABLE ID\", Trainable().trial_id)\n",
    "        print(\"TRAINABLE NAME\", Trainable().trial_name)\n",
    "        print(\"TRAINABLE IP\", Trainable()._local_ip)\n",
    "        print(\"TRAINABLE IP_PID\", Trainable().get_current_ip_pid())\n",
    "        print(\"TRAINABLE STATE\", Trainable().get_state())\n",
    "        \n",
    "        \n",
    "        print(\"TRAINABLE ID\", self.trial_id)\n",
    "        print(\"TRAINABLE NAME\", self.trial_name)\n",
    "        print(\"TRAINABLE IP\", self._local_ip)\n",
    "        print(\"TRAINABLE IP_PID\", self.get_current_ip_pid())\n",
    "        print(\"TRAINABLE STATE\", self.get_state())\n",
    "        \n",
    "        self.config = config\n",
    "        #filename = Path(\"./envs/V1/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "        #filename = Path(\"./envs/V2/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "        filename = Path(\"/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\") \n",
    "        filename_abs= filename.resolve()\n",
    "\n",
    "        self.train_mode=True\n",
    "        def start_unity_env(filename, no_graphics=True):\n",
    "            env = None\n",
    "\n",
    "            def start_unity_env_id(filename, no_graphics=True, worker_id=0):\n",
    "                try:\n",
    "                    env = UnityEnvironment(file_name=str(filename_abs),no_graphics=no_graphics, worker_id=worker_id)\n",
    "                    print(\"Started UnityEnvironment on worker id {}\".format(worker_id))\n",
    "                    return True, env\n",
    "                except UnityTimeOutException as e:\n",
    "                    print(e)\n",
    "                    return False, None\n",
    "\n",
    "            max_worker_id=10\n",
    "            for i in range(max_worker_id):\n",
    "                env_started, env = start_unity_env_id(filename, no_graphics=True, worker_id=i)\n",
    "                if env_started:\n",
    "                    print(env)\n",
    "                    return env\n",
    "                time.sleep(1)\n",
    "\n",
    "            return None\n",
    "\n",
    "        self.env = start_unity_env(filename=str(filename_abs), no_graphics=True)\n",
    "        self.training_name='_lrA_' +str(config['lr_actor'])+ '_lrC_' +str(config['lr_critic'])\n",
    "        \n",
    "        #==========================================================================\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "\n",
    "        # get the default brain\n",
    "        self.brain_name = self.env.brain_names[0]\n",
    "        brain = self.env.brains[self.brain_name]\n",
    "        print('Brain Name:', self.brain_name)\n",
    "        print('Port:', self.env.port)\n",
    "        # reset the environment\n",
    "        env_info = self.env.reset(train_mode=self.train_mode)[self.brain_name]\n",
    "        # number of agents\n",
    "        num_agents = len(env_info.agents)\n",
    "        print('Number of agents:', num_agents)\n",
    "        # size of each action\n",
    "        action_size = brain.vector_action_space_size\n",
    "        print('Size of each action:', action_size)\n",
    "        # examine the state space \n",
    "        states = env_info.vector_observations\n",
    "        state_size = states.shape[1]\n",
    "        print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "        print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "        #ep_tot_ts = []\n",
    "        average_score_over=100\n",
    "        self.num_agents = len(env_info.agents)\n",
    "        config['num_agents']=num_agents\n",
    "\n",
    "\n",
    "        self.agent = Agent(state_size=state_size,\n",
    "                      action_size=action_size,\n",
    "                      random_seed=config['random_seed'],\n",
    "                      config=config,\n",
    "                      device=device)\n",
    "\n",
    "\n",
    "        self.scores_deque = deque(maxlen=average_score_over)\n",
    "        self.scores = []\n",
    "        self.best_score = 0.0\n",
    "        self.i_episode = 0\n",
    "        \n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        #===================================================================\n",
    "\n",
    "        agent_scores = self.run_episode(self.env, self.agent, self.config, self.num_agents, self.brain_name)\n",
    "\n",
    "        avg_score = np.mean(agent_scores) \n",
    "        self.scores_deque.append(avg_score)   \n",
    "        self.scores.append(avg_score)\n",
    "\n",
    "        avg_100_scores = np.mean(self.scores_deque)\n",
    "\n",
    "        #Save successful agents\n",
    "        if avg_100_scores >= 30.0:\n",
    "                print(\"Success!\")\n",
    "                torch.save(self.agent.actor_local.state_dict(), \"successful_checkpoint_actor\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")   \n",
    "                torch.save(self.agent.critic_local.state_dict(), \"successful_checkpoint_critic\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\") \n",
    "                pickle.dump(self.scores, open('successful_scores'+self.training_name+\"_\"+str(self.i_episode)+'.pkl', 'wb'))\n",
    "\n",
    "        if avg_score > self.best_score:\n",
    "            print(\"Saving New Best Score: {}\".format(avg_score))\n",
    "            torch.save(self.agent.actor_local.state_dict(), \"checkpoint_actor_best\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "            torch.save(self.agent.critic_local.state_dict(), \"checkpoint_critic_best\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "            self.best_score = avg_score\n",
    "\n",
    "\n",
    "        if False:\n",
    "            print(\"Learning Samples: mean: {} : n_sample : {}\".format(self.agent.mean_learning_sample_reward, self.agent.n_learning_samples))\n",
    "            avg_rewards_learning_sample = self.agent.mean_learning_sample_reward/ self.agent.n_learning_samples\n",
    "            print('\\rAverage Reward in Internal Learning Samples: {}'.format(avg_rewards_learning_sample))\n",
    "\n",
    "        #Get average episodic scores\n",
    "        if self.i_episode % self.config['print_every'] == 0:\n",
    "\n",
    "            print('\\rScore Queue {},\\t Mean: {:.5f}'.format(self.scores_deque, avg_100_scores))\n",
    "            print('\\rEpisode {},\\t Noise: {}'.format(self.i_episode,1.0))#agent.noise.state))\n",
    "\n",
    "        self.i_episode += 1\n",
    "        #==========================================================================\n",
    "        \n",
    "        import os\n",
    "        \n",
    "        results = {\"avg_100_score\" : avg_100_scores,\n",
    "                   \"best_score\" : self.best_score,\n",
    "                   \"i_episode\" : self.i_episode,\n",
    "                   \"episode_avg_score\" : avg_score,\n",
    "                   \"os_cwd\" :  os.getcwd()}\n",
    "        return results\n",
    "        \n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        torch.save(self.agent.actor_local.state_dict(), \"checkpoint_actor_ray\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "        torch.save(self.agent.critic_local.state_dict(), \"checkpoint_critic_ray\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "        pickle.dump(self.scores, open('scores'+self.training_name+\"_\"+str(self.i_episode)+'.pkl', 'wb'))\n",
    "    \n",
    "    def cleanup(self):\n",
    "        self.env.close()\n",
    "        del(self.env)\n",
    "    \n",
    "    def run_episode(self, env, agent, config, num_agents, brain_name):\n",
    "        env_info = env.reset(train_mode=self.train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        agent_scores = np.zeros(num_agents) \n",
    "        #print(f'Starting Episode {i_episode}') \n",
    "        for t in range(config['max_t']):\n",
    "            #print(t)\n",
    "\n",
    "            #noise_weight = np.clip(avg_score/30*-1+1.0, 0.0, 1.0)\n",
    "            actions = agent.act(states, add_noise=True, noise_weight=1.0)\n",
    "            env_infos_avail = env.step(actions)\n",
    "            #print('Env Infos', env_infos_avail)\n",
    "            env_infos = env_infos_avail[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            if t%config['train_every_ts'] == 0:\n",
    "                agent.step(states,\n",
    "                           actions,\n",
    "                           rewards,\n",
    "                           next_states,\n",
    "                           dones,\n",
    "                           add_replay_flag=True,\n",
    "                           learn_flag=True,\n",
    "                           learn_repeat=config['train_repeated'])\n",
    "            else:\n",
    "                agent.step(states,\n",
    "                           actions,\n",
    "                           rewards,\n",
    "                           next_states,\n",
    "                           dones,\n",
    "                           add_replay_flag=True,\n",
    "                           learn_flag=False,\n",
    "                           learn_repeat=config['train_repeated'])\n",
    "\n",
    "            states = next_states\n",
    "            agent_scores += rewards\n",
    "            #if True in dones:\n",
    "            #    ep_tot_ts.append(t)\n",
    "            #    break\n",
    "\n",
    "            #if t % 100 == 0:\n",
    "            #    print('\\r {} ts \\tAverage Score: {:.2f}, Noise: {}'.format(t, np.mean(agent_scores), 1))#agent.noise.state))\n",
    "\n",
    "\n",
    "        return agent_scores  \n",
    "        \n",
    "\n",
    "config = {'buffer_size' : int(1e6),\n",
    "          'batch_size' : tune.grid_search([64, 128, 256]),\n",
    "          'gamma' : 0.95,\n",
    "          'tau' : 1e-3,\n",
    "          #'lr_actor' : 1e-3,\n",
    "          #'lr_critic' : 1e-4,\n",
    "          'lr_actor' : tune.grid_search([1e-2, 1e-3, 1e-4]),\n",
    "          'lr_critic' : tune.grid_search([1e-3, 1e-4, 1e-5]),\n",
    "          #'weight_decay' : 0.0,\n",
    "          'weight_decay' : 0.000008,\n",
    "          'theta' : 0.15,\n",
    "          'num_agents' : 20,\n",
    "          'random_seed' : 10,\n",
    "          'train_every_ts' : 10,\n",
    "          'train_repeated' : 40,\n",
    "          'checkpoint_every_n_episodes': 100,\n",
    "          'print_every' : 100,\n",
    "          'max_t' : 1500,\n",
    "          'ray_tune' : True}\n",
    "\n",
    "\n",
    "\n",
    "MyTrainable_with_gpu = tune.with_resources(MyTrainable, {\"gpu\": 1.0})\n",
    "tuner = tune.Tuner(MyTrainable_with_gpu,\n",
    "                   param_space=config,\n",
    "                   run_config=RunConfig(local_dir=\"/data1/Projects/ray_results\",\n",
    "                                        stop={\"training_iteration\": 5},\n",
    "                                        log_to_file=True,\n",
    "                                        checkpoint_config=CheckpointConfig(checkpoint_frequency=config['checkpoint_every_n_episodes'],\n",
    "                                                                           checkpoint_at_end=True)),\n",
    "                  tune_config=TuneConfig(max_concurrent_trials=1))\n",
    "results = tuner.fit()\n",
    "\n",
    "print(results.get_best_result(metric=\"avg_100_score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06451a5-180e-493b-9a44-dbd9b0a54b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_run_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ba956-4176-4a62-8ce4-00c41529e7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68138b5-d4d0-471d-81f2-d66a3f449e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf78f2e-1bf8-42ce-b9a9-97b9909f88ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a53b85-ced2-412a-aa99-44918c756867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b100f1-348a-42f5-9552-0b5473701bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47be909-3cd2-4938-a2c4-ab50fc696896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e08eff-032e-4b67-a122-6aa8c8950f18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started UnityEnvironment on worker id 0\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "Tuning Run Index 0\n",
      "Batch Size:  64  LR Actor:  0.01  LR Critic:  0.001\n",
      "cuda:0\n",
      "Brain Name: ReacherBrain\n",
      "Port: 5005\n",
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n",
      "Score Queue deque([0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 0,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.0, 'best_score': 0.0, 'i_episode': 1, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.00000\n",
      "Episode 2,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.0, 'best_score': 0.0, 'i_episode': 3, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Saving New Best Score: 0.7499999832361937\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.30000\n",
      "Episode 4,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.29999999329447746, 'best_score': 0.7499999832361937, 'i_episode': 5, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.21429\n",
      "Episode 6,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21428570949605533, 'best_score': 0.7499999832361937, 'i_episode': 7, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Saving New Best Score: 1.4999999664723873\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.33333\n",
      "Episode 8,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.3333333258827527, 'best_score': 1.4999999664723873, 'i_episode': 9, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.34091\n",
      "Episode 10,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.34090908328917896, 'best_score': 1.4999999664723873, 'i_episode': 11, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.28846\n",
      "Episode 12,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.28846153201392066, 'best_score': 1.4999999664723873, 'i_episode': 13, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.25000\n",
      "Episode 14,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.24999999441206455, 'best_score': 1.4999999664723873, 'i_episode': 15, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22059\n",
      "Episode 16,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.22058823036358638, 'best_score': 1.4999999664723873, 'i_episode': 17, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.19737\n",
      "Episode 18,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.1973684166411036, 'best_score': 1.4999999664723873, 'i_episode': 19, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.21429\n",
      "Episode 20,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21428570949605533, 'best_score': 1.4999999664723873, 'i_episode': 21, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22826\n",
      "Episode 22,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.22826086446318938, 'best_score': 1.4999999664723873, 'i_episode': 23, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Saving New Best Score: 2.249999949708581\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0], maxlen=100),\t Mean: 0.30000\n",
      "Episode 24,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.29999999329447746, 'best_score': 2.249999949708581, 'i_episode': 25, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.30556\n",
      "Episode 26,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.30555554872585666, 'best_score': 2.249999949708581, 'i_episode': 27, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.33621\n",
      "Episode 28,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.3362068890369144, 'best_score': 2.249999949708581, 'i_episode': 29, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.31452\n",
      "Episode 30,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.31451612200227475, 'best_score': 2.249999949708581, 'i_episode': 31, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.31818\n",
      "Episode 32,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.31818181106990034, 'best_score': 2.249999949708581, 'i_episode': 33, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.32143\n",
      "Episode 34,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.321428564244083, 'best_score': 2.249999949708581, 'i_episode': 35, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.32432\n",
      "Episode 36,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.3243243170751108, 'best_score': 2.249999949708581, 'i_episode': 37, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.30769\n",
      "Episode 38,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.30769230081484866, 'best_score': 2.249999949708581, 'i_episode': 39, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.31098\n",
      "Episode 40,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.31097560280525105, 'best_score': 2.249999949708581, 'i_episode': 41, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.29651\n",
      "Episode 42,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2965116212794254, 'best_score': 2.249999949708581, 'i_episode': 43, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.28333\n",
      "Episode 44,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2833333270003398, 'best_score': 2.249999949708581, 'i_episode': 45, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.28723\n",
      "Episode 46,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.28723403613301035, 'best_score': 2.249999949708581, 'i_episode': 47, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.29082\n",
      "Episode 48,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2908163200303608, 'best_score': 2.249999949708581, 'i_episode': 49, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873], maxlen=100),\t Mean: 0.30882\n",
      "Episode 50,\t Episode Average Score: 1.4999999664723873\n",
      "{'avg_100_score': 0.3088235225090209, 'best_score': 2.249999949708581, 'i_episode': 51, 'episode_avg_score': 1.4999999664723873, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.31132\n",
      "Episode 52,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.31132074775842, 'best_score': 2.249999949708581, 'i_episode': 53, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.31364\n",
      "Episode 54,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.3136363566260446, 'best_score': 2.249999949708581, 'i_episode': 55, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.30263\n",
      "Episode 56,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.3026315721830255, 'best_score': 2.249999949708581, 'i_episode': 57, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.29237\n",
      "Episode 58,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.29237287482088903, 'best_score': 2.249999949708581, 'i_episode': 59, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.28279\n",
      "Episode 60,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2827868789251222, 'best_score': 2.249999949708581, 'i_episode': 61, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.27381\n",
      "Episode 62,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.27380951768940404, 'best_score': 2.249999949708581, 'i_episode': 63, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.27692\n",
      "Episode 64,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2769230707333638, 'best_score': 2.249999949708581, 'i_episode': 65, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.29104\n",
      "Episode 66,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2910447696140453, 'best_score': 2.249999949708581, 'i_episode': 67, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.29348\n",
      "Episode 68,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2934782543098149, 'best_score': 2.249999949708581, 'i_episode': 69, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.28521\n",
      "Episode 70,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2852112612306652, 'best_score': 2.249999949708581, 'i_episode': 71, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.28767\n",
      "Episode 72,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2876712264467592, 'best_score': 2.249999949708581, 'i_episode': 73, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.30000\n",
      "Episode 74,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.29999999329447746, 'best_score': 2.249999949708581, 'i_episode': 75, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.29221\n",
      "Episode 76,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.29220778567643907, 'best_score': 2.249999949708581, 'i_episode': 77, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.28481\n",
      "Episode 78,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.28481012021627605, 'best_score': 2.249999949708581, 'i_episode': 79, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.27778\n",
      "Episode 80,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2777777715689606, 'best_score': 2.249999949708581, 'i_episode': 81, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.27108\n",
      "Episode 82,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2710843312901905, 'best_score': 2.249999949708581, 'i_episode': 83, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.26471\n",
      "Episode 84,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.26470587643630367, 'best_score': 2.249999949708581, 'i_episode': 85, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.26724\n",
      "Episode 86,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2672413733370345, 'best_score': 2.249999949708581, 'i_episode': 87, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.26124\n",
      "Episode 88,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.26123594921710114, 'best_score': 2.249999949708581, 'i_episode': 89, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.25549\n",
      "Episode 90,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25549449978375827, 'best_score': 2.249999949708581, 'i_episode': 91, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.25000\n",
      "Episode 92,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.24999999441206455, 'best_score': 2.249999949708581, 'i_episode': 93, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24474\n",
      "Episode 94,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.24473683663496845, 'best_score': 2.249999949708581, 'i_episode': 95, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.25515\n",
      "Episode 96,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2551546334721071, 'best_score': 2.249999949708581, 'i_episode': 97, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.25000\n",
      "Episode 98,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.24999999441206455, 'best_score': 2.249999949708581, 'i_episode': 99, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.26250\n",
      "Episode 100,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 101, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.27000\n",
      "Episode 102,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2699999939650297, 'best_score': 2.249999949708581, 'i_episode': 103, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.25500\n",
      "Episode 104,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 105, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.26250\n",
      "Episode 106,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 107, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 108,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 109, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 110,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 111, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 112,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 113, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24750\n",
      "Episode 114,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 115, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.25500\n",
      "Episode 116,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 117, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.26250\n",
      "Episode 118,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 119, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.25500\n",
      "Episode 120,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 121, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([2.249999949708581, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.25500\n",
      "Episode 122,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 123, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 124,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 125, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 126,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 127, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 128,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 129, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 130,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 131, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 132,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 133, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873], maxlen=100),\t Mean: 0.21750\n",
      "Episode 134,\t Episode Average Score: 1.4999999664723873\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 135, 'episode_avg_score': 1.4999999664723873, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 136,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 137, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 138,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 139, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 140,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 141, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581], maxlen=100),\t Mean: 0.24000\n",
      "Episode 142,\t Episode Average Score: 2.249999949708581\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 143, 'episode_avg_score': 2.249999949708581, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        , 14.99999966, 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 144,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 145, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 146,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 147, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 148,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 149, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 150,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 151, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 152,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 153, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 154,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 155, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 156,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 157, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 158,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 159, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 160,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 161, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 162,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 163, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , 14.99999966,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 164,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 165, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.23250\n",
      "Episode 166,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 167, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 168,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 169, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 170,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 171, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 172,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 173, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.21750\n",
      "Episode 174,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 175, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 176,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 177, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 178,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 179, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 180,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 181, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 182,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 183, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 184,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 185, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 186,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 187, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 188,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 189, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 190,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 191, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 192,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 193, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 194,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 195, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 196,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 197, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 198,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 199, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 200,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 201, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 202,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 203, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 204,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 205, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 206,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 207, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.23250\n",
      "Episode 208,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 209, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 210,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 211, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 212,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 213, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 214,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 215, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 216,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 217, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 218,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 219, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 220,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 221, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 222,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 223, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 224,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 225, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 226,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 227, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 228,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 229, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873], maxlen=100),\t Mean: 0.27000\n",
      "Episode 230,\t Episode Average Score: 1.4999999664723873\n",
      "{'avg_100_score': 0.2699999939650297, 'best_score': 2.249999949708581, 'i_episode': 231, 'episode_avg_score': 1.4999999664723873, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 1.4999999664723873, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0], maxlen=100),\t Mean: 0.27000\n",
      "Episode 232,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2699999939650297, 'best_score': 2.249999949708581, 'i_episode': 233, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.26250\n",
      "Episode 234,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 235, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.25500\n",
      "Episode 236,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 237, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.26250\n",
      "Episode 238,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 239, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 2.249999949708581, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.26250\n",
      "Episode 240,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 241, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 242,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 243, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 244,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 245, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 246,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 247, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 248,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 249, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 250,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 251, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24750\n",
      "Episode 252,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 253, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 254,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 255, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 256,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 257, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 258,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 259, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 260,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 261, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 262,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 263, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 264,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 265, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 266,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 267, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 268,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 269, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24750\n",
      "Episode 270,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 271, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 272,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 273, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 274,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 275, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 276,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 277, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 278,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 279, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 280,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 281, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 282,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 283, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 284,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 285, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.25500\n",
      "Episode 286,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 287, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , 14.99999966]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.26250\n",
      "Episode 288,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 289, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.26250\n",
      "Episode 290,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 291, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.26250\n",
      "Episode 292,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2624999941326678, 'best_score': 2.249999949708581, 'i_episode': 293, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.25500\n",
      "Episode 294,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 295, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.25500\n",
      "Episode 296,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 297, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 298,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 299, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 300,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 301, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 302,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 303, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 304,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 305, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 306,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 307, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 308,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 309, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 310,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 311, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.24000\n",
      "Episode 312,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 313, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.24000\n",
      "Episode 314,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23999999463558197, 'best_score': 2.249999949708581, 'i_episode': 315, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 316,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 317, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 318,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 319, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.25500\n",
      "Episode 320,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.25499999430030584, 'best_score': 2.249999949708581, 'i_episode': 321, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.24750\n",
      "Episode 322,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 323, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.24750\n",
      "Episode 324,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2474999944679439, 'best_score': 2.249999949708581, 'i_episode': 325, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.23250\n",
      "Episode 326,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.23249999480322003, 'best_score': 2.249999949708581, 'i_episode': 327, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 328,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 329, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873], maxlen=100),\t Mean: 0.21750\n",
      "Episode 330,\t Episode Average Score: 1.4999999664723873\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 331, 'episode_avg_score': 1.4999999664723873, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , 14.99999966,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 332,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 333, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 334,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 335, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 336,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 337, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 338,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 339, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 340,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 341, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.19500\n",
      "Episode 342,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 343, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 344,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 345, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 346,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 347, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 348,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 349, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.19500\n",
      "Episode 350,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 351, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.18750\n",
      "Episode 352,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.18749999580904841, 'best_score': 2.249999949708581, 'i_episode': 353, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873], maxlen=100),\t Mean: 0.19500\n",
      "Episode 354,\t Episode Average Score: 1.4999999664723873\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 355, 'episode_avg_score': 1.4999999664723873, 'agent_scores': array([14.99999966,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.20250\n",
      "Episode 356,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 357, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.21000\n",
      "Episode 358,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 359, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 360,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 361, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 362,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 363, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 364,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 365, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.19500\n",
      "Episode 366,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 367, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 368,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 369, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.19500\n",
      "Episode 370,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 371, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.19500\n",
      "Episode 372,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 373, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.19500\n",
      "Episode 374,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 375, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.18750\n",
      "Episode 376,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.18749999580904841, 'best_score': 2.249999949708581, 'i_episode': 377, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.19500\n",
      "Episode 378,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 379, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.18750\n",
      "Episode 380,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.18749999580904841, 'best_score': 2.249999949708581, 'i_episode': 381, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.19500\n",
      "Episode 382,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 383, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , 14.99999966,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 384,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 385, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 386,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 387, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.20250\n",
      "Episode 388,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 389, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 390,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 391, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 392,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 393, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       14.99999966,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 394,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 395, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 396,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 397, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 398,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 399, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 400,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 401, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21750\n",
      "Episode 402,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.21749999513849616, 'best_score': 2.249999949708581, 'i_episode': 403, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 404,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 405, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 406,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 407, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.7499999832361937, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.21000\n",
      "Episode 408,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.20999999530613422, 'best_score': 2.249999949708581, 'i_episode': 409, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], maxlen=100),\t Mean: 0.20250\n",
      "Episode 410,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2024999954737723, 'best_score': 2.249999949708581, 'i_episode': 411, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937], maxlen=100),\t Mean: 0.19500\n",
      "Episode 412,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.19499999564141035, 'best_score': 2.249999949708581, 'i_episode': 413, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , 14.99999966,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.7499999832361937], maxlen=100),\t Mean: 0.22500\n",
      "Episode 414,\t Episode Average Score: 0.7499999832361937\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 415, 'episode_avg_score': 0.7499999832361937, 'agent_scores': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , 14.99999966,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n",
      "Score Queue deque([0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4999999664723873, 0.0, 0.7499999832361937, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 1.4999999664723873, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.7499999832361937, 0.7499999832361937, 0.0, 0.0, 0.7499999832361937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999832361937, 2.249999949708581, 0.7499999832361937, 0.7499999832361937, 0.0], maxlen=100),\t Mean: 0.22500\n",
      "Episode 416,\t Episode Average Score: 0.0\n",
      "{'avg_100_score': 0.2249999949708581, 'best_score': 2.249999949708581, 'i_episode': 417, 'episode_avg_score': 0.0, 'agent_scores': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.]), 'os_cwd': '/mnt/data1/Projects/Udacity_RL/p2'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df16f72a98dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mep_id\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print_every'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0mstep_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-df16f72a98dc>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m#===================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0magent_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mavg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-df16f72a98dc>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self, env, agent, config, num_agents, brain_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                            \u001b[0madd_replay_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                            \u001b[0mlearn_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                            learn_repeat=config['train_repeated'])\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 agent.step(states,\n",
      "\u001b[0;32m/mnt/data1/Projects/Udacity_RL/p2/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, states, actions, rewards, next_states, dones, add_replay_flag, learn_flag, learn_repeat)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from unityagents.exception import UnityTimeOutException\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "class MyTrainable():\n",
    "    def __init__(self, config, env):\n",
    "        self.setup(config, env)\n",
    "    \n",
    "    def setup(self, config, env):\n",
    "        \n",
    "        self.config = config\n",
    "        self.env = env\n",
    "        self.training_name=config['training_name']\n",
    "        \n",
    "        \n",
    "        os.mkdir(config['training_name'])\n",
    "        self.checkpoint_dir = self.training_name + '/'\n",
    "        #self.training_name='_bz_' +str(config['batch_size'])+ '_lrA_' +str(config['lr_actor'])+ '_lrC_' +str(config['lr_critic'])\n",
    "        self\n",
    "        #==========================================================================\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "        self.train_mode = config['train_mode']\n",
    "        \n",
    "        \n",
    "        # get the default brain\n",
    "        self.brain_name = self.env.brain_names[0]\n",
    "        brain = self.env.brains[self.brain_name]\n",
    "        print('Brain Name:', self.brain_name)\n",
    "        print('Port:', self.env.port)\n",
    "        # reset the environment\n",
    "        env_info = self.env.reset(train_mode=self.train_mode)[self.brain_name]\n",
    "        # number of agents\n",
    "        num_agents = len(env_info.agents)\n",
    "        print('Number of agents:', num_agents)\n",
    "        # size of each action\n",
    "        action_size = brain.vector_action_space_size\n",
    "        print('Size of each action:', action_size)\n",
    "        # examine the state space \n",
    "        states = env_info.vector_observations\n",
    "        state_size = states.shape[1]\n",
    "        print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "        print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "        #ep_tot_ts = []\n",
    "        average_score_over=100\n",
    "        self.num_agents = len(env_info.agents)\n",
    "        config['num_agents']=num_agents\n",
    "\n",
    "\n",
    "        self.agent = Agent(state_size=state_size,\n",
    "                      action_size=action_size,\n",
    "                      random_seed=config['random_seed'],\n",
    "                      config=config,\n",
    "                      device=device)\n",
    "\n",
    "\n",
    "        self.scores_deque = deque(maxlen=average_score_over)\n",
    "        self.scores = []\n",
    "        self.best_score = 0.0\n",
    "        self.i_episode = 0\n",
    "        \n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        #===================================================================\n",
    "\n",
    "        agent_scores = self.run_episode(self.env, self.agent, self.config, self.num_agents, self.brain_name)\n",
    "\n",
    "        avg_score = np.mean(agent_scores) \n",
    "        self.scores_deque.append(avg_score)   \n",
    "        self.scores.append(avg_score)\n",
    "\n",
    "        avg_100_scores = np.mean(self.scores_deque)\n",
    "\n",
    "        #Save successful agents\n",
    "        if avg_100_scores >= 30.0:\n",
    "                print(\"Success!\")\n",
    "                torch.save(self.agent.actor_local.state_dict(), self.checkpoint_dir+\"successful_checkpoint_actor\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")   \n",
    "                torch.save(self.agent.critic_local.state_dict(), self.checkpoint_dir+\"successful_checkpoint_critic\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\") \n",
    "                pickle.dump(self.scores, open(self.checkpoint_dir+'successful_scores'+self.training_name+\"_\"+str(self.i_episode)+'.pkl', 'wb'))\n",
    "\n",
    "        if avg_score > self.best_score:\n",
    "            print(\"Saving New Best Score: {}\".format(avg_score))\n",
    "            torch.save(self.agent.actor_local.state_dict(), self.checkpoint_dir+\"checkpoint_actor_best\"+self.training_name+\".pth\")\n",
    "            torch.save(self.agent.critic_local.state_dict(), self.checkpoint_dir+\"checkpoint_critic_best\"+self.training_name+\".pth\")\n",
    "            self.best_score = avg_score\n",
    "\n",
    "\n",
    "        if False:\n",
    "            print(\"Learning Samples: mean: {} : n_sample : {}\".format(self.agent.mean_learning_sample_reward, self.agent.n_learning_samples))\n",
    "            avg_rewards_learning_sample = self.agent.mean_learning_sample_reward/ self.agent.n_learning_samples\n",
    "            print('\\rAverage Reward in Internal Learning Samples: {}'.format(avg_rewards_learning_sample))\n",
    "\n",
    "        #Get average episodic scores\n",
    "        if self.i_episode % self.config['print_every'] == 0:\n",
    "\n",
    "            print('\\rScore Queue {},\\t Mean: {:.5f}'.format(self.scores_deque, avg_100_scores))\n",
    "            print('\\rEpisode {},\\t Episode Average Score: {}'.format(self.i_episode,avg_score))#agent.noise.state))\n",
    "\n",
    "        self.i_episode += 1\n",
    "        #==========================================================================\n",
    "        \n",
    "        import os\n",
    "        \n",
    "        results = {\"avg_100_score\" : avg_100_scores,\n",
    "                   \"best_score\" : self.best_score,\n",
    "                   \"i_episode\" : self.i_episode,\n",
    "                   \"episode_avg_score\" : avg_score,\n",
    "                   \"agent_scores\" : agent_scores,\n",
    "                   \"os_cwd\" :  os.getcwd()}\n",
    "        return results\n",
    "        \n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        torch.save(self.agent.actor_local.state_dict(), self.checkpoint_dir+\"checkpoint_actor_ray\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "        torch.save(self.agent.critic_local.state_dict(), self.checkpoint_dir+\"checkpoint_critic_ray\"+self.training_name+\"_\"+str(self.i_episode)+\".pth\")\n",
    "        pickle.dump(self.scores, open(self.checkpoint_dir+'scores'+self.training_name+\"_\"+str(self.i_episode)+'.pkl', 'wb'))\n",
    "    \n",
    "    def cleanup(self):\n",
    "        return\n",
    "    \n",
    "    def run_episode(self, env, agent, config, num_agents, brain_name):\n",
    "        env_info = env.reset(train_mode=self.train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        agent_scores = np.zeros(num_agents) \n",
    "        #print(f'Starting Episode {i_episode}') \n",
    "        for t in range(config['max_t']):\n",
    "            #print(t)\n",
    "\n",
    "            #noise_weight = np.clip(avg_score/30*-1+1.0, 0.0, 1.0)\n",
    "            actions = agent.act(states, add_noise=True, noise_weight=1.0)\n",
    "            env_infos_avail = env.step(actions)\n",
    "            #print('Env Infos', env_infos_avail)\n",
    "            env_infos = env_infos_avail[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            if t%config['train_every_ts'] == 0:\n",
    "                agent.step(states,\n",
    "                           actions,\n",
    "                           rewards,\n",
    "                           next_states,\n",
    "                           dones,\n",
    "                           add_replay_flag=True,\n",
    "                           learn_flag=True,\n",
    "                           learn_repeat=config['train_repeated'])\n",
    "            else:\n",
    "                agent.step(states,\n",
    "                           actions,\n",
    "                           rewards,\n",
    "                           next_states,\n",
    "                           dones,\n",
    "                           add_replay_flag=True,\n",
    "                           learn_flag=False,\n",
    "                           learn_repeat=config['train_repeated'])\n",
    "\n",
    "            states = next_states\n",
    "            agent_scores += rewards\n",
    "            #if True in dones:\n",
    "            #    ep_tot_ts.append(t)\n",
    "            #    break\n",
    "\n",
    "            #if t % 100 == 0:\n",
    "            #    print('\\r {} ts \\tAverage Score: {:.2f}, Noise: {}'.format(t, np.mean(agent_scores), 1))#agent.noise.state))\n",
    "\n",
    "\n",
    "        return agent_scores  \n",
    "        \n",
    "\n",
    "\n",
    "#filename = Path(\"./envs/V1/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "#filename = Path(\"./envs/V2/Reacher_Windows_x86_64/Reacher.exe\") \n",
    "filename = Path(\"/mnt/data1/Projects/Udacity_RL/p2/envs/V2/Reacher.x86_64\") \n",
    "filename_abs= filename.resolve()\n",
    "\n",
    "def start_unity_env(filename, no_graphics=True):\n",
    "    env = None\n",
    "\n",
    "    def start_unity_env_id(filename, no_graphics=True, worker_id=0):\n",
    "        try:\n",
    "            env = UnityEnvironment(file_name=str(filename_abs),no_graphics=no_graphics, worker_id=worker_id)\n",
    "            print(\"Started UnityEnvironment on worker id {}\".format(worker_id))\n",
    "            return True, env\n",
    "        except UnityTimeOutException as e:\n",
    "            print(e)\n",
    "            return False, None\n",
    "\n",
    "    max_worker_id=10\n",
    "    for i in range(max_worker_id):\n",
    "        env_started, env = start_unity_env_id(filename, no_graphics=True, worker_id=i)\n",
    "        if env_started:\n",
    "            print(env)\n",
    "            return env\n",
    "        time.sleep(1)\n",
    "\n",
    "    return None\n",
    "\n",
    "env = start_unity_env(filename=str(filename_abs), no_graphics=True)\n",
    "\n",
    "\n",
    "\n",
    "base_config = {'buffer_size' : int(1e6),\n",
    "          'batch_size' : [64, 128, 256],\n",
    "          'gamma' : 0.95,\n",
    "          'tau' : 1e-3,\n",
    "          #'lr_actor' : 1e-3,\n",
    "          #'lr_critic' : 1e-4,\n",
    "          'lr_actor' : [1e-2, 1e-3, 1e-4],\n",
    "          'lr_critic' : [1e-3, 1e-4, 1e-5],\n",
    "          #'weight_decay' : 0.0,\n",
    "          'weight_decay' : 0.000008,\n",
    "          'theta' : 0.15,\n",
    "          'num_agents' : 20,\n",
    "          'random_seed' : 10,\n",
    "          'train_every_ts' : 10,\n",
    "          'train_repeated' : 40,\n",
    "          'checkpoint_every_n_episodes': 50,\n",
    "          'print_every' : 2,\n",
    "          'max_t' : 1500,\n",
    "          'ray_tune' : True,\n",
    "          'train_mode' : True}\n",
    "\n",
    "tuning_results = {}\n",
    "\n",
    "from copy import deepcopy\n",
    "for bz_idx, bz in enumerate(base_config['batch_size']):\n",
    "    for lra_idx, lra in enumerate(base_config['lr_actor']):\n",
    "        for lrc_idx, lrc in enumerate(base_config['lr_critic']):\n",
    "            config = deepcopy(base_config)\n",
    "            config['batch_size'] = bz\n",
    "            config['lr_actor'] = lra\n",
    "            config['lr_critic'] = lrc\n",
    "            \n",
    "            tuning_run_results = []\n",
    "            print('Tuning Run Index', str(bz_idx * lra_idx * lrc_idx))\n",
    "            print('Batch Size: ', bz, ' LR Actor: ', lra, ' LR Critic: ', lrc)\n",
    "            training_name = 'TUNE1_bz_' +str(config['batch_size'])+ '_lrA_' +str(config['lr_actor'])+ '_lrC_' +str(config['lr_critic'])\n",
    "            config['training_name'] = training_name\n",
    "            \n",
    "            trainable = MyTrainable(config, env)\n",
    "            \n",
    "            \n",
    "            training_episodes=500\n",
    "            for ep_id in range(training_episodes):\n",
    "\n",
    "                if ep_id % config['print_every'] == 0:\n",
    "                    print(trainable.step())\n",
    "                else:\n",
    "                    step_results = trainable.step()\n",
    "                    tuning_run_results.append(step_results)\n",
    "                    \n",
    "                    \n",
    "                if ep_id % config['checkpoint_every_n_episodes'] == 0:\n",
    "                    trainable.save_checkpoint('')\n",
    "            trainable.save_checkpoint('')\n",
    "            trainable.cleanup()\n",
    "            tuning_results[training_name] = tuning_run_results\n",
    "print(len(tuning_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85688803-acbd-455c-bda9-cb19d3e473a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc35a4b7-3472-4e07-9031-3ab6aaa79fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('TUNE1_bz_64_lrA_0.01_lrC_0.001/scoresTUNE1_bz_64_lrA_0.01_lrC_0.001_50.pkl', 'rb') as f:\n",
    "    scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df632da-0d2e-4cb7-aad4-a4075de8381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14bf7e57-5403-4eb6-98c9-80015964706a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6abff9-9b02-4e0a-aac6-114494409804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
